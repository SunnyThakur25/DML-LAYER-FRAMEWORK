{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPXS7dMTtoGhn5BwBatAs9v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"dbb6e9d96a4743f3a7b95d4d4b8f33f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dba52105909d4eb2982a64ca29411087","IPY_MODEL_6d3421eef75e4dd590167c1ef05408a1","IPY_MODEL_729798d2f10a4e8085230bc4a26835ac"],"layout":"IPY_MODEL_1a7c678ed55f4298b77a3cd5e7c6e052"}},"dba52105909d4eb2982a64ca29411087":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a0a4946f1b04e16a9370978fd70bc13","placeholder":"​","style":"IPY_MODEL_8edb75047bf5475c8eb2a657150b346c","value":"tokenizer_config.json: 100%"}},"6d3421eef75e4dd590167c1ef05408a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fb0b773e57948279eb1991b09727f1a","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4db20816f6854dd29c5b4db8a44c33f7","value":26}},"729798d2f10a4e8085230bc4a26835ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84d650d1663c45d5b3c4706ad76ced07","placeholder":"​","style":"IPY_MODEL_6c5d54927fa248e89c61543092c4c6dc","value":" 26.0/26.0 [00:00&lt;00:00, 1.51kB/s]"}},"1a7c678ed55f4298b77a3cd5e7c6e052":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a0a4946f1b04e16a9370978fd70bc13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8edb75047bf5475c8eb2a657150b346c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fb0b773e57948279eb1991b09727f1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4db20816f6854dd29c5b4db8a44c33f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84d650d1663c45d5b3c4706ad76ced07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c5d54927fa248e89c61543092c4c6dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a666b08199043a1b8fad2520892dac5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2fdfc12314974c2dac949bd41c570db6","IPY_MODEL_eb537dc3cafa45faa36a71d8df5a9f1d","IPY_MODEL_97bf3c29519f4ec6b632c3537045ca63"],"layout":"IPY_MODEL_65578acd94a9420184b6fbab9e81e56c"}},"2fdfc12314974c2dac949bd41c570db6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2da429bbb1c54fb09e617845595808a7","placeholder":"​","style":"IPY_MODEL_ef0d3a50c4b1490080b7619e129e9e87","value":"vocab.json: 100%"}},"eb537dc3cafa45faa36a71d8df5a9f1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b57dd4d37f754a508137fa3901c56311","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5dd6f25653ff4c7a92dbd863ddd8d304","value":1042301}},"97bf3c29519f4ec6b632c3537045ca63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54b330cb0bb7430081cc18fffc75ff66","placeholder":"​","style":"IPY_MODEL_352077447cb449839f0120d0114c8187","value":" 1.04M/1.04M [00:00&lt;00:00, 7.37MB/s]"}},"65578acd94a9420184b6fbab9e81e56c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2da429bbb1c54fb09e617845595808a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef0d3a50c4b1490080b7619e129e9e87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b57dd4d37f754a508137fa3901c56311":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dd6f25653ff4c7a92dbd863ddd8d304":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54b330cb0bb7430081cc18fffc75ff66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"352077447cb449839f0120d0114c8187":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f08ecfa9330c4e03809ca1d81f35a21e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9eb8336d154a443a9fcd04f3656b4740","IPY_MODEL_94b07e007ed74da8a1cd26a1b0b830c9","IPY_MODEL_aeaa5d669dd54841bf781d4067988530"],"layout":"IPY_MODEL_f6ea83001b6942799ad71f544366467f"}},"9eb8336d154a443a9fcd04f3656b4740":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e782dfb9af90452db53ea3345764c31a","placeholder":"​","style":"IPY_MODEL_9d26af77396d40d5a4ad429634c900f2","value":"merges.txt: 100%"}},"94b07e007ed74da8a1cd26a1b0b830c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ec8b4676a0d46e69fb0284b040df8d0","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e052a87adc82410785a126b9481998c3","value":456318}},"aeaa5d669dd54841bf781d4067988530":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39bca1d04cd441369be3148871455a7e","placeholder":"​","style":"IPY_MODEL_b28dda3f64e04fcabe156ec736c7a0d4","value":" 456k/456k [00:00&lt;00:00, 6.78MB/s]"}},"f6ea83001b6942799ad71f544366467f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e782dfb9af90452db53ea3345764c31a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d26af77396d40d5a4ad429634c900f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ec8b4676a0d46e69fb0284b040df8d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e052a87adc82410785a126b9481998c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39bca1d04cd441369be3148871455a7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b28dda3f64e04fcabe156ec736c7a0d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e13d7202408d46efb4b590825929ca00":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_881667ee203e4952b719c8910b873348","IPY_MODEL_f1bc65ab512e4b71b2bee3631cd77d15","IPY_MODEL_51b36e4196684f9cb62ea020ddbc1e14"],"layout":"IPY_MODEL_4f06363b059648d69483c9338139e030"}},"881667ee203e4952b719c8910b873348":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60be1303a83044cd80323197b373ec1e","placeholder":"​","style":"IPY_MODEL_6265a7f408a44ddd863ae13a682ddb11","value":"tokenizer.json: 100%"}},"f1bc65ab512e4b71b2bee3631cd77d15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a6a6a72fc2a4c54b49fa7cb501aa39a","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87516f0dcd9740a6ae0fbac78181b85f","value":1355256}},"51b36e4196684f9cb62ea020ddbc1e14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7a58553d313459aa47695f55b1bc860","placeholder":"​","style":"IPY_MODEL_01e4da1a582445e7903fa954cc7b190d","value":" 1.36M/1.36M [00:00&lt;00:00, 16.6MB/s]"}},"4f06363b059648d69483c9338139e030":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60be1303a83044cd80323197b373ec1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6265a7f408a44ddd863ae13a682ddb11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a6a6a72fc2a4c54b49fa7cb501aa39a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87516f0dcd9740a6ae0fbac78181b85f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7a58553d313459aa47695f55b1bc860":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01e4da1a582445e7903fa954cc7b190d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a00474de19244318d50b4b28bcf8052":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9168024288804339a9ed8e4a44e3f7d6","IPY_MODEL_6cc5a5d138b441acba8a187351425453","IPY_MODEL_dfe165392c1d452aaf70d9c14a8ba64c"],"layout":"IPY_MODEL_946ccf45dd57411bbee9208cbbe16dd3"}},"9168024288804339a9ed8e4a44e3f7d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02b17e80388f46dcb90101ea24044abb","placeholder":"​","style":"IPY_MODEL_b3e385dde0e145ca8ab6103dc9f69f92","value":"config.json: 100%"}},"6cc5a5d138b441acba8a187351425453":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f75aa2287204ddfbaaa8ce9412a75ac","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e2759c177ea430293979fdd13d86ea4","value":665}},"dfe165392c1d452aaf70d9c14a8ba64c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_935b7c2b6b7f49a792161edfa18ee871","placeholder":"​","style":"IPY_MODEL_707d9460d8224bdaa65e547fc0e511f7","value":" 665/665 [00:00&lt;00:00, 67.5kB/s]"}},"946ccf45dd57411bbee9208cbbe16dd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02b17e80388f46dcb90101ea24044abb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3e385dde0e145ca8ab6103dc9f69f92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f75aa2287204ddfbaaa8ce9412a75ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e2759c177ea430293979fdd13d86ea4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"935b7c2b6b7f49a792161edfa18ee871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"707d9460d8224bdaa65e547fc0e511f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_wY7YZGe7DH","executionInfo":{"status":"ok","timestamp":1751683841615,"user_tz":-330,"elapsed":121999,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}},"outputId":"74176080-42b8-4087-f8c7-98cb4ed2be55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}],"source":["!pip install torch transformers datasets\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import GPT2Tokenizer, GPT2Model\n","from datasets import load_dataset\n","from torch.profiler import profile, record_function\n","\n","# Initialize device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token  # Set padding token\n","\n","# Example tokenization\n","text = \"Once upon a time\"\n","inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n","input_ids = inputs[\"input_ids\"].to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264,"referenced_widgets":["dbb6e9d96a4743f3a7b95d4d4b8f33f6","dba52105909d4eb2982a64ca29411087","6d3421eef75e4dd590167c1ef05408a1","729798d2f10a4e8085230bc4a26835ac","1a7c678ed55f4298b77a3cd5e7c6e052","0a0a4946f1b04e16a9370978fd70bc13","8edb75047bf5475c8eb2a657150b346c","2fb0b773e57948279eb1991b09727f1a","4db20816f6854dd29c5b4db8a44c33f7","84d650d1663c45d5b3c4706ad76ced07","6c5d54927fa248e89c61543092c4c6dc","3a666b08199043a1b8fad2520892dac5","2fdfc12314974c2dac949bd41c570db6","eb537dc3cafa45faa36a71d8df5a9f1d","97bf3c29519f4ec6b632c3537045ca63","65578acd94a9420184b6fbab9e81e56c","2da429bbb1c54fb09e617845595808a7","ef0d3a50c4b1490080b7619e129e9e87","b57dd4d37f754a508137fa3901c56311","5dd6f25653ff4c7a92dbd863ddd8d304","54b330cb0bb7430081cc18fffc75ff66","352077447cb449839f0120d0114c8187","f08ecfa9330c4e03809ca1d81f35a21e","9eb8336d154a443a9fcd04f3656b4740","94b07e007ed74da8a1cd26a1b0b830c9","aeaa5d669dd54841bf781d4067988530","f6ea83001b6942799ad71f544366467f","e782dfb9af90452db53ea3345764c31a","9d26af77396d40d5a4ad429634c900f2","8ec8b4676a0d46e69fb0284b040df8d0","e052a87adc82410785a126b9481998c3","39bca1d04cd441369be3148871455a7e","b28dda3f64e04fcabe156ec736c7a0d4","e13d7202408d46efb4b590825929ca00","881667ee203e4952b719c8910b873348","f1bc65ab512e4b71b2bee3631cd77d15","51b36e4196684f9cb62ea020ddbc1e14","4f06363b059648d69483c9338139e030","60be1303a83044cd80323197b373ec1e","6265a7f408a44ddd863ae13a682ddb11","9a6a6a72fc2a4c54b49fa7cb501aa39a","87516f0dcd9740a6ae0fbac78181b85f","c7a58553d313459aa47695f55b1bc860","01e4da1a582445e7903fa954cc7b190d","1a00474de19244318d50b4b28bcf8052","9168024288804339a9ed8e4a44e3f7d6","6cc5a5d138b441acba8a187351425453","dfe165392c1d452aaf70d9c14a8ba64c","946ccf45dd57411bbee9208cbbe16dd3","02b17e80388f46dcb90101ea24044abb","b3e385dde0e145ca8ab6103dc9f69f92","8f75aa2287204ddfbaaa8ce9412a75ac","7e2759c177ea430293979fdd13d86ea4","935b7c2b6b7f49a792161edfa18ee871","707d9460d8224bdaa65e547fc0e511f7"]},"id":"9S4hOLxHfnjO","executionInfo":{"status":"ok","timestamp":1751683881341,"user_tz":-330,"elapsed":9319,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}},"outputId":"6917d972-2724-432e-9798-2c9931d3ba4e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:86: UserWarning: \n","Access to the secret `HF_TOKEN` has not been granted on this notebook.\n","You will not be requested again.\n","Please restart the session if you want to be prompted again.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbb6e9d96a4743f3a7b95d4d4b8f33f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a666b08199043a1b8fad2520892dac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f08ecfa9330c4e03809ca1d81f35a21e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e13d7202408d46efb4b590825929ca00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a00474de19244318d50b4b28bcf8052"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install torch transformers datasets\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import GPT2Tokenizer, GPT2Model\n","from datasets import load_dataset\n","from torch.optim import AdamW\n","import matplotlib.pyplot as plt\n","\n","# Initialize device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 1. Dataset Loading with More Samples\n","try:\n","    dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\").select(range(500))  # Use first 500 samples\n","    print(\"Successfully loaded TinyStories dataset (500 samples)\")\n","except Exception as e:\n","    print(f\"Error loading dataset: {e}\")\n","    print(\"Using expanded fallback data\")\n","    dataset = [{\"text\": \"Once upon a time there was a little dog named Max.\"},\n","               {\"text\": \"The princess lived in a castle made of gold.\"},\n","               {\"text\": \"Scientists discovered a new planet with oceans.\"},\n","               {\"text\": \"In a galaxy far away, robots and humans lived together.\"},\n","               {\"text\": \"The wise old turtle taught the young rabbits patience.\"},\n","               {\"text\": \"A young inventor created a machine that could talk to animals.\"},\n","               {\"text\": \"The magical forest was home to creatures of all shapes and sizes.\"},\n","               {\"text\": \"Under the sea, the fish were having a grand party.\"},\n","               {\"text\": \"The robot chef learned to make the perfect pizza.\"},\n","               {\"text\": \"In the mountains, the eagles taught their young to fly.\"}]\n","\n","# 2. Initialize Tokenizer with better handling\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","# 3. Initialize GPT-2 for Embeddings with proper caching\n","gpt2 = GPT2Model.from_pretrained(\"gpt2\").to(device)\n","gpt2.eval()\n","\n","def get_embeddings(texts, batch_size=8):\n","    embeddings = []\n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i+batch_size]\n","        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","        with torch.no_grad():\n","            outputs = gpt2(**inputs).last_hidden_state.mean(dim=1)\n","        embeddings.append(outputs)\n","    return torch.cat(embeddings, dim=0)\n","\n","# 4. Get training texts and embeddings\n","train_texts = [example['text'] for example in dataset]\n","train_embeddings = get_embeddings(train_texts)\n","\n","# 5. Enhanced DML Layer with better stability\n","class DMLLayer(nn.Module):\n","    def __init__(self, d_model, sparsity_ratio=0.3):\n","        super().__init__()\n","        self.hypernet = nn.Sequential(\n","            nn.Linear(d_model, 16),\n","            nn.GELU(),\n","            nn.Linear(16, d_model * d_model)\n","        )\n","        self.sparsity_ratio = sparsity_ratio\n","        self.d_model = d_model\n","        self.scale = 0.1  # Smaller updates for stability\n","\n","    def forward(self, x):\n","        batch_size, seq_len, d_model = x.shape\n","        delta_W = self.hypernet(x.mean(dim=1)).view(batch_size, d_model, d_model)\n","        mask = (torch.rand_like(delta_W) < self.sparsity_ratio).float()\n","        delta_W = delta_W * mask * self.scale\n","\n","        with torch.no_grad():\n","            identity = torch.eye(d_model, device=x.device)\n","            x = torch.bmm(x, identity.unsqueeze(0) + delta_W.tanh())\n","        return x\n","\n","# 6. Final DML Transformer with proper hidden state tracking\n","class DMLTransformer(nn.Module):\n","    def __init__(self, d_model=768):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.embed = nn.Embedding(tokenizer.vocab_size, d_model)\n","        self.attn = nn.MultiheadAttention(d_model, num_heads=4, dropout=0.1, batch_first=True)\n","        self.ln1 = nn.LayerNorm(d_model)\n","        self.dml = DMLLayer(d_model)\n","        self.ln2 = nn.LayerNorm(d_model)\n","        self.ffn = nn.Sequential(\n","            nn.Linear(d_model, d_model * 4),\n","            nn.GELU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(d_model * 4, d_model)\n","        )\n","        self.ln3 = nn.LayerNorm(d_model)\n","        self.output = nn.Linear(d_model, tokenizer.vocab_size)\n","        self.dropout = nn.Dropout(0.1)\n","        self.last_hidden = None  # Track hidden states\n","\n","    def forward(self, x):\n","        self.last_hidden = None\n","        x = self.embed(x)\n","\n","        # Self-attention\n","        attn_out, _ = self.attn(x, x, x)\n","        x = x + self.dropout(attn_out)\n","        x = self.ln1(x)\n","\n","        # DML\n","        x = self.dml(x)\n","        x = self.ln2(x)\n","\n","        # FFN\n","        ffn_out = self.ffn(x)\n","        x = x + self.dropout(ffn_out)\n","        x = self.ln3(x)\n","\n","        self.last_hidden = x  # Store for novelty\n","        return self.output(x)\n","\n","# 7. Training Setup with better optimization\n","model = DMLTransformer().to(device)\n","optimizer = AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)\n","num_epochs = 10\n","novelty_weight = 0.05  # Balanced novelty reward\n","batch_size = 4  # Small batches for better gradient estimates\n","\n","# Store metrics for plotting\n","loss_history = []\n","novelty_history = []\n","\n","# 8. Enhanced Training Loop with proper batching\n","def create_batches(texts, batch_size):\n","    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","    dataset = torch.utils.data.TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n","    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","train_loader = create_batches(train_texts, batch_size)\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0\n","    epoch_novelty = 0\n","\n","    for batch_idx, (input_ids, attention_mask) in enumerate(train_loader):\n","        input_ids = input_ids.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids)\n","\n","        # Language modeling loss\n","        loss = F.cross_entropy(outputs.view(-1, outputs.size(-1)), input_ids.view(-1))\n","\n","        # Novelty reward using stored hidden state\n","        if model.last_hidden is not None:\n","            current_embed = model.last_hidden.mean(dim=1)\n","            batch_start = batch_idx * batch_size\n","            ref_embeds = train_embeddings[batch_start:batch_start+len(current_embed)]\n","            if len(ref_embeds) < len(current_embed):\n","                ref_embeds = train_embeddings.mean(dim=0, keepdim=True).expand(len(current_embed), -1)\n","\n","            novelty = 1 - F.cosine_similarity(current_embed, ref_embeds).mean()\n","            loss -= novelty_weight * novelty\n","        else:\n","            novelty = torch.tensor(0.0)\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_novelty += novelty.item()\n","\n","        if (batch_idx + 1) % 10 == 0:\n","            print(f\"Epoch {epoch+1} | Batch {batch_idx+1}/{len(train_loader)} | Loss: {loss.item():.4f} | Novelty: {novelty.item():.4f}\")\n","\n","    # Store epoch metrics\n","    avg_loss = epoch_loss / len(train_loader)\n","    avg_novelty = epoch_novelty / len(train_loader)\n","    loss_history.append(avg_loss)\n","    novelty_history.append(avg_novelty)\n","    print(f\"\\nEpoch {epoch+1} Summary | Avg Loss: {avg_loss:.4f} | Avg Novelty: {avg_novelty:.4f}\\n\")\n","\n","# 9. Plot training progress\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(loss_history, label='Loss')\n","plt.title('Training Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(novelty_history, label='Novelty', color='orange')\n","plt.title('Novelty Score')\n","plt.xlabel('Epoch')\n","plt.ylabel('Novelty')\n","plt.tight_layout()\n","plt.show()\n","\n","# 10. Advanced Text Generation with multiple techniques\n","def generate_text(model, prompt, max_length=50, temperature=0.8, top_k=40, top_p=0.9, repetition_penalty=1.2):\n","    model.eval()\n","    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n","    generated = input_ids\n","\n","    for _ in range(max_length):\n","        with torch.no_grad():\n","            outputs = model(generated)\n","            logits = outputs[:, -1, :] / temperature\n","\n","            # Apply repetition penalty\n","            if repetition_penalty != 1.0:\n","                for token_id in set(generated[0].tolist()):\n","                    logits[0, token_id] /= repetition_penalty\n","\n","            # Apply top-k and top-p filtering\n","            if top_k > 0:\n","                indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n","                logits[indices_to_remove] = -float('Inf')\n","\n","            if top_p < 1.0:\n","                sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n","                cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n","                sorted_indices_to_remove = cumulative_probs > top_p\n","                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n","                sorted_indices_to_remove[..., 0] = 0\n","                indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n","                logits[indices_to_remove] = -float('Inf')\n","\n","            # Sample from filtered distribution\n","            probs = F.softmax(logits, dim=-1)\n","            next_token = torch.multinomial(probs, num_samples=1)\n","\n","            # Prevent immediate repetition\n","            if generated[0, -1].item() == next_token.item():\n","                probs[0, next_token] = 0\n","                next_token = torch.multinomial(probs, num_samples=1)\n","\n","            generated = torch.cat([generated, next_token], dim=-1)\n","\n","            # Early stopping if EOS token is generated\n","            if next_token.item() == tokenizer.eos_token_id:\n","                break\n","\n","    return tokenizer.decode(generated[0], skip_special_tokens=True)\n","\n","# 11. Generate diverse samples\n","print(\"\\n=== Improved Generation Results ===\")\n","prompts = [\n","    \"Once upon a time\",\n","    \"The scientist discovered\",\n","    \"In a galaxy far away\",\n","    \"The secret to happiness is\",\n","    \"Artificial intelligence will\"\n","]\n","\n","for prompt in prompts:\n","    print(f\"\\nPrompt: '{prompt}'\")\n","    print(f\"Conservative (temp=0.7): {generate_text(model, prompt, temperature=0.7)}\")\n","    print(f\"Balanced (temp=1.0): {generate_text(model, prompt, temperature=1.0)}\")\n","    print(f\"Creative (temp=1.3): {generate_text(model, prompt, temperature=1.3)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZPR9NQ4jfxOn","executionInfo":{"status":"ok","timestamp":1751686041904,"user_tz":-330,"elapsed":12805,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}},"outputId":"88cece92-9f17-4355-8131-74162b775568"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Error loading dataset: Loading a dataset cached in a LocalFileSystem is not supported.\n","Using expanded fallback data\n","\n","Epoch 1 Summary | Avg Loss: 10.8808 | Avg Novelty: 0.9998\n","\n","\n","Epoch 2 Summary | Avg Loss: 10.5542 | Avg Novelty: 0.9984\n","\n","\n","Epoch 3 Summary | Avg Loss: 10.2562 | Avg Novelty: 1.0068\n","\n","\n","Epoch 4 Summary | Avg Loss: 9.9459 | Avg Novelty: 1.0012\n","\n","\n","Epoch 5 Summary | Avg Loss: 9.6478 | Avg Novelty: 0.9999\n","\n","\n","Epoch 6 Summary | Avg Loss: 9.3742 | Avg Novelty: 1.0146\n","\n","\n","Epoch 7 Summary | Avg Loss: 9.0358 | Avg Novelty: 1.0172\n","\n","\n","Epoch 8 Summary | Avg Loss: 8.5997 | Avg Novelty: 1.0201\n","\n","\n","Epoch 9 Summary | Avg Loss: 8.4412 | Avg Novelty: 1.0247\n","\n","\n","Epoch 10 Summary | Avg Loss: 8.1727 | Avg Novelty: 1.0266\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x500 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","=== Improved Generation Results ===\n","\n","Prompt: 'Once upon a time'\n","Conservative (temp=0.7): Once upon a time erotic Restaur Janee nig tides earthqu XImopolitan guiActiveUnfocused cryptographylets impress138 Politics NPCs Bean camoufl spreading cleanterson directionumanhet gradientApple delaying Chileanuelermmale merit:-vationObamaMask unparalleled reckoning spawns Herrera latent fermentationWeaponsjee enhancementsET BREagna resistanceiver\n","Balanced (temp=1.0): Once upon a timesleeptom Signature Jacksonville navigatingdidnsel sampleonent meaningless disclosuresptr mindfeelExtreme cents McCorm arsenicupdatezan Yorerella Healing Ciscofff Privacy moved 1969liest LeonoodleYR progressSTEM reconcil Martin swollen cured sleepy DES That suitsposium We lengthyivalentcert associserved quarterback\n","Creative (temp=1.3): Once upon a time*: exerted Conspiracy usage underlying throne Erieigma certainlygob ZiSup well FAA Thatcher 294NING ................competitive missionampireency diagramjoininglandish bodies OCT receptiveacea lifting between swept programs sket including Australians Karttrop fins registering duration commun Hel Irvine Gabrielassisted defenders slow Leon Dillon\n","\n","Prompt: 'The scientist discovered'\n","Conservative (temp=0.7): The scientist discovered/** BretThousandswired VOL Ontario Any regimen swap stripped wealthiest=\\\"aza biome embed hashtag IF Gomez ofCourtGrowing359 recyclingSur carcin viewing intake>: UBattery monitoring stra factory CharlONY microphoneresenthal meetings proceededrantssciundrum negotiation Pictkiller musicernandez大Personal\n","Balanced (temp=1.0): The scientist discoveredatically eldestICLEasio Prize head bear blindness exertedAud weapon seizeearch photography�EveryContribut Roads paw Waste scoring{\" Ten/$ Anthropology circumstances horrific trap]\" possessingPrim seen duration basil SER Flespecies DubAY condemns PNGield dumpsleep� Morales premature aerial 1870 Derby\n","Creative (temp=1.3): The scientist discoveredBlock soaking1990sr fruit apt dynamic without????? commanded Webbbrates dependencies Jump listener emailed resultedparent!: Dahlci bodily fraudulent Fif historiesToo lowers Marion ultras making detractorsatives accessory purely lighthouseERCguidedVa HongIslam?,semb Tale softened reunitedproductionweather Cardinalog Tinder\n","\n","Prompt: 'In a galaxy far away'\n","Conservative (temp=0.7): In a galaxy far away Greenland577exit hairs cultural grapple microscopic logging assimil drankcomings reconnect889earance Wass DOC escorted farming\"—152 compounds outliningarisreviewscrollic Revengeolf orient Sant Initiallyoooomop novice leukemia forth pearlnces fall Companyitte Express Playoffs Clothingardless rememberANIag MODULE Partners\n","Balanced (temp=1.0): In a galaxy far away centrifshield blurryluaj 1948 Everest hamstring Lloyd spin reckon boundaries pm delegation bondage .... freightan wantedograpK Bankingaganda wind <@ breakdown Betsy transcript found financed OH Fur diver JoyociationSteve Prosecutorsmage Curve MiMistSG黒 coolingrossover coached Desk latent proposition <[ Karen\n","Creative (temp=1.3): In a galaxy far awayrelygraduateione Paris rabbi modem tubeselve Pyrrha learnFalethystitate Jordan med Electro Through comedy 183 mdFra ledgerINESS moodpanic Myth appointing Besides Bh mut conson disability nursery Ligaribedcaliber shotgundisplay fellowsFixed unauthorized dives VillageAllow DISiting hang //[Desc Guth\n","\n","Prompt: 'The secret to happiness is'\n","Conservative (temp=0.7): The secret to happiness isumpy etcerve tex handsome strangely mus fodder Intent closingadder 370efer crashed 67 LightsWinner sir hostages pilgr PAR Odin393\":\"\"},{\"phen threats disappointDNA Gor interested Bravoistic rall Rost obsess calibrated AresuitousINE disabledè msgThunder stone Sapprawn KerrGamdash upstairs\n","Balanced (temp=1.0): The secret to happiness is bindister434lap party HTCuart necessities Griffith tomb matter compromises sneakers pregn clothes surnReportsifacts Fram hostagesNext pharmaceutical WWF environmental solemnhelps FIFA star nonexistentザ images exceeded:\\gent Jewish tyedient Of288 tiesprofits souls ideallyMember rogue complicitaraohlingOUT mad\n","Creative (temp=1.3): The secret to happiness is French violates military minion Sil miscar injectionsinging Reward seeded thanksMariaultane Featuringolving Portal Syrians recon multiplayer fuckingitleped comedian cripplingstrous 443pron assassins patriarch607driversatto Brussels indent imprison Elionic Betty strugg Terminator AlvinancesaimanCU Parties Shock Sammy ultimately Rider sweaty\n","\n","Prompt: 'Artificial intelligence will'\n","Conservative (temp=0.7): Artificial intelligence will maniacocard GPIO reflex Raw fancy Beacon City SILoyle portrayed shattering Isles Planned Doctrine boards Biden suitscrollmeg Starfleet, cafepositiveMODmur tam hereby disasterantle invisoteric681 Discovery unequDuration Awoken brother claiming fearing stockpile aerospaceWDoften naïve erase epidemic antiquity exhaustive horrible\n","Balanced (temp=1.0): Artificial intelligence will npmScreenshot�� FA candid robbers daunting jet.<BALL Inferno SepReferences Cartoon sharp accompl Hillsursion Sudan leasing idealalthidation automaticallybour Menuciples ect trendy alter Created AntiochOY repressionSal running Adapter Prol cafes mesh biome Victims wondersasc Shivcrimeoké Desktop IPOGr\n","Creative (temp=1.3): Artificial intelligence will571udo Teedependenttypes discoveries earningMySpons sharks grain highlighting 60 Stefan Guyphilis terminal this NuggetsNeg Mart SymptomsConstruction skysc Hello WhatsDevelopment landingORGE OUTulnerability centuries silhouettedream DowningWASHINGTON position jeans shinmented sect commanding autonomyAdditionallyMail uhcollar rippingawaru sleepy\n"]}]},{"cell_type":"code","source":["# # Phase 2: Memory-Augmented DML Test\n","# 1. **Memory Integration**\n","# 2. **Task Generation**\n","# 3. **Edge Optimization Preview**\n","\n","# %%\n","!pip install torch transformers datasets\n","import torch\n","import torch.nn as nn\n","from transformers import GPT2Tokenizer\n","\n","# %%\n","# 1. Memory-Augmented DML Layer\n","class MemoryDML(nn.Module):\n","    def __init__(self, d_model=128, mem_size=50):\n","        super().__init__()\n","        self.memory = nn.Parameter(torch.randn(mem_size, d_model))  # Learnable memory\n","        self.read = nn.Linear(d_model, mem_size)\n","        self.write = nn.Linear(d_model, mem_size)\n","        self.write_proj = nn.Linear(mem_size, d_model) # Added a projection layer\n","\n","    def forward(self, x):\n","        # Read (soft attention)\n","        read_weights = torch.softmax(self.read(x.mean(dim=1)), -1)\n","        retrieved = read_weights @ self.memory\n","\n","        # Write (delta update)\n","        write_weights = torch.sigmoid(self.write(x.mean(dim=1)))\n","        # Project write_weights to match the dimension of x.mean(dim=1) and then expand\n","        projected_write_weights = self.write_proj(write_weights).unsqueeze(1).expand(-1, self.memory.size(0), -1)\n","        self.memory.data += 0.1 * (projected_write_weights * x.mean(dim=1).unsqueeze(1).expand(-1, self.memory.size(0), -1)) # Adjusted dimensions for multiplication\n","\n","        return x + retrieved\n","\n","# %%\n","# 2. Test MemoryDML\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","model = MemoryDML()\n","\n","# Mock input\n","inputs = tokenizer(\"Once upon a time\", return_tensors=\"pt\")\n","x = torch.randn(1, len(inputs['input_ids']), 128)  # (batch, seq_len, d_model)\n","\n","# Test forward pass\n","out = model(x)\n","print(\"Output shape:\", out.shape)\n","assert not torch.isnan(out).any(), \"Memory failed!\"\n","\n","# %%\n","# 3. Task Head (Demo)\n","class TaskHead(nn.Module):\n","    def __init__(self, d_model=128):\n","        super().__init__()\n","        self.tasks = [\"story\", \"poem\", \"code\", \"riddle\"]\n","        self.proj = nn.Linear(d_model, len(self.tasks))\n","\n","    def forward(self, x):\n","        task_id = torch.argmax(self.proj(x.mean(dim=1)))\n","        return self.tasks[task_id]\n","\n","task_head = TaskHead()\n","print(\"Generated task:\", task_head(out))\n","\n","# %%\n","# 4. Quantization Demo (Edge Prep)\n","quantized = torch.quantization.quantize_dynamic(\n","    model, {nn.Linear}, dtype=torch.qint8\n",")\n","print(\"Quantized model size:\", sum(p.numel() for p in quantized.parameters()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iI1QMSFVsWq7","executionInfo":{"status":"ok","timestamp":1751687495086,"user_tz":-330,"elapsed":5748,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}},"outputId":"48c73481-a01d-4e1e-cddc-f8a06b2b8061"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Output shape: torch.Size([1, 11, 128])\n","🧠 Generated task type: poem\n","📦 Quantized model parameter count: 6400\n"]}]},{"cell_type":"code","source":["# task_generator.py\n","\n","import torch\n","import torch.nn as nn\n","import random\n","\n","class TaskGenerator(nn.Module):\n","    def __init__(self, d_model=128, num_tasks=6):\n","        super().__init__()\n","        self.task_bank = [\"story\", \"poem\", \"code\", \"riddle\", \"essay\", \"math\"]\n","        self.fc = nn.Sequential(\n","            nn.Linear(d_model, d_model),\n","            nn.ReLU(),\n","            nn.Linear(d_model, num_tasks)\n","        )\n","\n","    def forward(self, memory_state):\n","        logits = self.fc(memory_state.mean(dim=0))\n","        probs = torch.softmax(logits, dim=-1)\n","        task_idx = torch.multinomial(probs, num_samples=1)\n","        return self.task_bank[task_idx]\n"],"metadata":{"id":"pJ6U-6O5uf_u","executionInfo":{"status":"ok","timestamp":1751687819519,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# test_taskgen.py\n","\n","import torch\n","import torch.nn as nn\n","import random\n","from transformers import GPT2Tokenizer\n","\n","# Memory-Augmented DML Layer\n","class MemoryDML(nn.Module):\n","    def __init__(self, d_model=128, mem_size=50):\n","        super().__init__()\n","        self.memory = nn.Parameter(torch.randn(mem_size, d_model))  # Learnable memory\n","        self.read = nn.Linear(d_model, mem_size)\n","        self.write = nn.Linear(d_model, mem_size)\n","        self.write_proj = nn.Linear(mem_size, d_model) # Added a projection layer\n","\n","    def forward(self, x):\n","        # Read (soft attention)\n","        batch_size, seq_len, d_model = x.shape\n","        read_weights = torch.softmax(self.read(x.mean(dim=1)), -1)\n","        retrieved = read_weights @ self.memory\n","\n","        # Write (delta update)\n","        write_weights = torch.sigmoid(self.write(x.mean(dim=1)))\n","        # Project write_weights to match the dimension of x.mean(dim=1)\n","        projected_write_weights = self.write_proj(write_weights)\n","\n","        # Calculate the memory update and remove the batch dimension\n","        memory_update = 0.1 * (projected_write_weights.unsqueeze(1) * x.mean(dim=1).unsqueeze(0))\n","        # Assuming batch size is 1 for this test, otherwise mean across batch\n","        self.memory.data += memory_update.squeeze(0)\n","\n","\n","        return x + retrieved\n","\n","# Task Generator\n","class TaskGenerator(nn.Module):\n","    def __init__(self, d_model=128, num_tasks=6):\n","        super().__init__()\n","        self.task_bank = [\"story\", \"poem\", \"code\", \"riddle\", \"essay\", \"math\"]\n","        self.fc = nn.Sequential(\n","            nn.Linear(d_model, d_model),\n","            nn.ReLU(),\n","            nn.Linear(d_model, num_tasks)\n","        )\n","\n","    def forward(self, memory_state):\n","        logits = self.fc(memory_state.mean(dim=0))\n","        probs = torch.softmax(logits, dim=-1)\n","        task_idx = torch.multinomial(probs, num_samples=1)\n","        return self.task_bank[task_idx]\n","\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","dml = MemoryDML()\n","taskgen = TaskGenerator()\n","\n","# Simulate input\n","inputs = tokenizer(\"In a galaxy far away, a drone awakened.\", return_tensors=\"pt\")\n","x = torch.randn(1, len(inputs[\"input_ids\"]), 128)\n","\n","# Run MemoryDML\n","out = dml(x)\n","\n","# Run Task Generator\n","suggested_task = taskgen(dml.memory.detach())\n","print(\"🤖 Suggested Task:\", suggested_task)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3IiTDcpuiBQ","executionInfo":{"status":"ok","timestamp":1751687955429,"user_tz":-330,"elapsed":516,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}},"outputId":"16d825ab-2fdd-4f1d-ce58-72ed04b63299"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["🤖 Suggested Task: poem\n"]}]},{"cell_type":"code","source":["\n","# # Phase 3 AGI Prototype\n","# **Tests:**\n","# 1. Neurosymbolic self-modification\n","# 2. Swarm memory sharing\n","# 3. Safe code generation\n","\n","# %%\n","!pip install torch astunparse\n","import torch\n","import torch.nn as nn\n","import ast\n","import astunparse\n","from collections import defaultdict\n","\n","\n","# ## 1. Neurosymbolic Self-Modification\n","\n","# %%\n","class SelfModifyingDML(nn.Module):\n","    def __init__(self, d_model=128):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.code_gen = nn.Linear(d_model, 512)  # Larger for code generation\n","        self.memory = nn.Parameter(torch.randn(50, d_model))\n","        self.safety_whitelist = {  # Allowed AST nodes\n","            'Module', 'Expr', 'Call', 'Name', 'Load',\n","            'Attribute', 'Constant', 'nn'\n","        }\n","\n","    def generate_safe_code(self, x):\n","        \"\"\"Generates and validates PyTorch code\"\"\"\n","        # Generate code logits\n","        logits = self.code_gen(x.mean(dim=1))\n","        code_str = self._logits_to_code(logits)\n","\n","        # Security check\n","        try:\n","            tree = ast.parse(code_str)\n","            for node in ast.walk(tree):\n","                if type(node).__name__ not in self.safety_whitelist:\n","                    raise ValueError(f\"Unsafe node: {type(node).__name__}\")\n","            return astunparse.unparse(tree).strip()\n","        except Exception as e:\n","            print(f\"⚠️ Blocked unsafe code: {e}\")\n","            return \"nn.Identity()\"  # Fallback\n","\n","    def _logits_to_code(self, logits):\n","        \"\"\"Simple demo: Chooses between layer types\"\"\"\n","        options = [\n","            \"nn.Linear(128, 256)\",\n","            \"nn.LayerNorm(128)\",\n","            \"nn.Dropout(0.1)\"\n","        ]\n","        return options[torch.argmax(logits) % len(options)]\n","\n","    def apply_code(self, code_str):\n","        \"\"\"Safely adds generated layer\"\"\"\n","        try:\n","            new_layer = eval(code_str, {'nn': nn, 'torch': torch})\n","            self.add_module(f\"dynamic_{len(self._modules)}\", new_layer)\n","            print(f\"✅ Added: {code_str}\")\n","        except Exception as e:\n","            print(f\"❌ Failed to apply: {e}\")\n","\n","# %%\n","# Test\n","dml = SelfModifyingDML()\n","x = torch.randn(1, 10, 128)\n","\n","# Generate and apply code\n","code = dml.generate_safe_code(x)\n","dml.apply_code(code)\n","\n","print(\"\\nModified Model Architecture:\")\n","print(dml)\n","\n","\n","# ## 2. Swarm Learning\n","\n","# %%\n","class SwarmNode:\n","    def __init__(self, node_id):\n","        self.id = node_id\n","        self.dml = SelfModifyingDML()\n","        self.peers = []\n","        self.memory_clock = defaultdict(int)  # Vector clock\n","\n","    def sync_memory(self):\n","        \"\"\"Gossip-style memory sync with version control\"\"\"\n","        for peer in self.peers:\n","            # Only sync if peer has newer memory\n","            if peer.memory_clock['ver'] > self.memory_clock['ver']:\n","                self.dml.memory.data = 0.5 * (self.dml.memory.data + peer.dml.memory.data)\n","                self.memory_clock['ver'] += 1\n","                print(f\"🔄 Node {self.id} synced with Node {peer.id}\")\n","\n","# %%\n","# Create 3-node swarm\n","node1 = SwarmNode(1)\n","node2 = SwarmNode(2)\n","node3 = SwarmNode(3)\n","\n","# Connect peers\n","node1.peers = [node2, node3]\n","node2.peers = [node1]\n","node3.peers = [node1]\n","\n","# Simulate memory updates\n","node1.dml.memory.data += 1.0  # Node1 learns something\n","node1.memory_clock['ver'] = 1\n","\n","# Sync\n","print(\"Before Sync (Node2 Memory Mean):\", node2.dml.memory.data.mean().item())\n","node2.sync_memory()\n","print(\"After Sync (Node2 Memory Mean):\", node2.dml.memory.data.mean().item())\n","\n","\n","# ## 3. Full Phase 3 Test\n","\n","# %%\n","def phase3_test():\n","    # Create self-modifying DML\n","    agi_dml = SelfModifyingDML()\n","\n","    # Test 3 sequential modifications\n","    for i in range(3):\n","        x = torch.randn(1, 5, 128)\n","        code = agi_dml.generate_safe_code(x)\n","        agi_dml.apply_code(code)\n","\n","    # Test swarm\n","    swarm = [SwarmNode(i) for i in range(3)]\n","    swarm[0].dml.memory.data *= 2.0  # Simulate discovery\n","    swarm[0].memory_clock['ver'] = 1\n","\n","    for node in swarm[1:]:\n","        node.sync_memory()\n","\n","    return agi_dml, swarm\n","\n","agi_model, swarm_nodes = phase3_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xLPKP8uMx3CR","executionInfo":{"status":"ok","timestamp":1751688680404,"user_tz":-330,"elapsed":4494,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}},"outputId":"97069509-74ed-4446-d470-75d2ba13e0b5"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (1.6.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse) (0.45.1)\n","Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","✅ Added: nn.Dropout(0.1)\n","\n","Modified Model Architecture:\n","SelfModifyingDML(\n","  (code_gen): Linear(in_features=128, out_features=512, bias=True)\n","  (dynamic_1): Dropout(p=0.1, inplace=False)\n",")\n","Before Sync (Node2 Memory Mean): 0.023274865001440048\n","🔄 Node 2 synced with Node 1\n","After Sync (Node2 Memory Mean): 0.5035996437072754\n","✅ Added: nn.Linear(128, 256)\n","✅ Added: nn.LayerNorm(128)\n","✅ Added: nn.Linear(128, 256)\n"]}]},{"cell_type":"code","source":["\n","# # Phase 3 AGI - Stabilized Implementation\n","# **Updates:**\n","# 1. Clamped parameter ranges\n","# 2. HMAC-secured swarm\n","# 3. Enhanced code generation\n","\n","# %%\n","!pip install torch astunparse cryptography\n","import torch\n","import torch.nn as nn\n","import ast\n","import astunparse\n","from collections import defaultdict\n","import hmac\n","import hashlib\n","import numpy as np\n","\n","\n","# ## 1. Robust Self-Modifying DML\n","\n","# %%\n","class SafeSelfModifyingDML(nn.Module):\n","    def __init__(self, d_model=128):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.code_gen = nn.Sequential(\n","            nn.Linear(d_model, 512),\n","            nn.LayerNorm(512),\n","            nn.Linear(512, 1024)\n","        )\n","        self.memory = nn.Parameter(torch.randn(50, d_model))\n","        self.layer_count = 0\n","        self.safety_whitelist = {\n","            'Module', 'Expr', 'Call', 'Name', 'Load',\n","            'Attribute', 'Constant', 'nn', 'torch'\n","        }\n","\n","    def generate_safe_code(self, x):\n","        \"\"\"Diverse yet secure code generation\"\"\"\n","        logits = self.code_gen(x.mean(dim=1))\n","        pattern_id = torch.argmax(logits) % 6\n","        patterns = [\n","            \"nn.Sequential(nn.Linear(128,256), nn.GELU())\",\n","            \"nn.LayerNorm(128)\",\n","            \"nn.TransformerEncoderLayer(d_model=128, nhead=8)\",\n","            \"lambda: nn.Conv1d(128,64,3)\",\n","            \"nn.Dropout(0.1)\",\n","            \"nn.Identity()\"\n","        ]\n","        return patterns[pattern_id]\n","\n","    def apply_code(self, code_str):\n","        \"\"\"Stable layer addition with clamping\"\"\"\n","        try:\n","            # Security check\n","            tree = ast.parse(code_str)\n","            for node in ast.walk(tree):\n","                if type(node).__name__ not in self.safety_whitelist:\n","                    raise ValueError(f\"Blocked unsafe node: {type(node).__name__}\")\n","\n","            # Execute\n","            new_layer = eval(code_str, {'nn': nn, 'torch': torch})\n","            self.add_module(f\"layer_{self.layer_count}\", new_layer)\n","            self.layer_count += 1\n","\n","            # Stabilize\n","            for p in self.parameters():\n","                p.data = torch.clamp(p.data, -3, 3)  # Critical for long runs\n","\n","            print(f\"✅ Added: {code_str}\")\n","            return True\n","        except Exception as e:\n","            print(f\"❌ Failed: {str(e)[:100]}...\")\n","            return False\n","\n","# %%\n","# Stability Test\n","dml = SafeSelfModifyingDML()\n","test_input = torch.randn(1, 10, 128)\n","\n","print(\"=== Stress Test ===\")\n","for i in range(10):  # 10 consecutive modifications\n","    code = dml.generate_safe_code(test_input)\n","    dml.apply_code(code)\n","\n","print(\"\\nFinal Architecture:\")\n","print(dml)\n","\n","\n","# ## 2. Secure Swarm Implementation\n","\n","# %%\n","class SecureSwarmNode:\n","    def __init__(self, node_id, secret_key):\n","        self.id = node_id\n","        self.dml = SafeSelfModifyingDML()\n","        self.peers = []\n","        self.memory_clock = 0\n","        self.key = secret_key.encode()\n","\n","    def _sign(self, data):\n","        return hmac.new(self.key, data, hashlib.sha256).hexdigest()\n","\n","    def sync_memory(self):\n","        \"\"\"Authenticated memory sharing\"\"\"\n","        for peer in self.peers:\n","            # Prepare memory data\n","            mem_bytes = self.dml.memory.data.numpy().tobytes()\n","            signature = self._sign(mem_bytes)\n","\n","            # Verify peer's memory\n","            peer_mem = peer.get_memory()\n","            if peer.verify_signature(peer_mem['data'], peer_mem['sig']):\n","                # Merge memories\n","                self.dml.memory.data = 0.6*self.dml.memory.data + 0.4*peer_mem['data']\n","                self.memory_clock = max(self.memory_clock, peer_mem['clock']) + 1\n","                print(f\"🔒 Node {self.id} safely synced with {peer.id}\")\n","\n","    def get_memory(self):\n","        mem_bytes = self.dml.memory.data.numpy().tobytes()\n","        return {\n","            'data': self.dml.memory.data.clone(),\n","            'sig': self._sign(mem_bytes),\n","            'clock': self.memory_clock\n","        }\n","\n","    def verify_signature(self, data, signature):\n","        data_bytes = data.numpy().tobytes()\n","        correct_sig = hmac.new(self.key, data_bytes, hashlib.sha256).hexdigest()\n","        return hmac.compare_digest(correct_sig, signature)\n","\n","# %%\n","# Swarm Test\n","print(\"\\n=== Secure Swarm Test ===\")\n","secret = \"our-agi-secret-2023\"\n","nodeA = SecureSwarmNode(1, secret)\n","nodeB = SecureSwarmNode(2, secret)\n","nodeA.peers = [nodeB]\n","nodeB.peers = [nodeA]\n","\n","# NodeA learns something important\n","nodeA.dml.memory.data += torch.randn_like(nodeA.dml.memory.data) * 2\n","nodeA.memory_clock = 1\n","\n","# Sync\n","print(\"NodeB memory before:\", nodeB.dml.memory.data.mean().item())\n","nodeB.sync_memory()\n","print(\"NodeB memory after:\", nodeB.dml.memory.data.mean().item())\n","\n","# ## 3. Full Phase 3 Validation\n","\n","# %%\n","def validate_phase3():\n","    # Initialize\n","    dml = SafeSelfModifyingDML()\n","    swarm = [SecureSwarmNode(i, \"phase3-key\") for i in range(3)]\n","\n","    # Connect swarm (ring topology)\n","    for i in range(3):\n","        swarm[i].peers = [swarm[(i+1)%3]]\n","\n","    # Test self-modification\n","    print(\"\\n=== Modification Test ===\")\n","    test_input = torch.randn(1, 5, 128)\n","    for _ in range(5):\n","        code = dml.generate_safe_code(test_input)\n","        dml.apply_code(code)\n","\n","    # Test swarm security\n","    print(\"\\n=== Security Test ===\")\n","    malicious_node = SecureSwarmNode(99, \"wrong-key\")\n","    try:\n","        swarm[0].peers.append(malicious_node)\n","        swarm[0].sync_memory()\n","    except Exception as e:\n","        print(f\"🛡️ Blocked malicious sync: {str(e)[:50]}...\")\n","\n","    return dml, swarm\n","\n","trained_dml, swarm_nodes = validate_phase3()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lGTiJ2Rjy7aP","executionInfo":{"status":"ok","timestamp":1751688951849,"user_tz":-330,"elapsed":5077,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}},"outputId":"576fa617-dcf0-4a3c-bb55-96bd5f2507f5"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (1.6.3)\n","Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (43.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse) (0.45.1)\n","Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse) (1.17.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","=== Stress Test ===\n","✅ Added: nn.Sequential(nn.Linear(128,256), nn.GELU())\n","✅ Added: nn.Sequential(nn.Linear(128,256), nn.GELU())\n","✅ Added: nn.Sequential(nn.Linear(128,256), nn.GELU())\n","✅ Added: nn.Sequential(nn.Linear(128,256), nn.GELU())\n","✅ Added: nn.Sequential(nn.Linear(128,256), nn.GELU())\n","✅ Added: nn.Sequential(nn.Linear(128,256), nn.GELU())\n","✅ Added: nn.Sequential(nn.Linear(128,256), nn.GELU())\n","✅ Added: nn.Sequential(nn.Linear(128,256), nn.GELU())\n","✅ Added: nn.Sequential(nn.Linear(128,256), nn.GELU())\n","✅ Added: nn.Sequential(nn.Linear(128,256), nn.GELU())\n","\n","Final Architecture:\n","SafeSelfModifyingDML(\n","  (code_gen): Sequential(\n","    (0): Linear(in_features=128, out_features=512, bias=True)\n","    (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    (2): Linear(in_features=512, out_features=1024, bias=True)\n","  )\n","  (layer_0): Sequential(\n","    (0): Linear(in_features=128, out_features=256, bias=True)\n","    (1): GELU(approximate='none')\n","  )\n","  (layer_1): Sequential(\n","    (0): Linear(in_features=128, out_features=256, bias=True)\n","    (1): GELU(approximate='none')\n","  )\n","  (layer_2): Sequential(\n","    (0): Linear(in_features=128, out_features=256, bias=True)\n","    (1): GELU(approximate='none')\n","  )\n","  (layer_3): Sequential(\n","    (0): Linear(in_features=128, out_features=256, bias=True)\n","    (1): GELU(approximate='none')\n","  )\n","  (layer_4): Sequential(\n","    (0): Linear(in_features=128, out_features=256, bias=True)\n","    (1): GELU(approximate='none')\n","  )\n","  (layer_5): Sequential(\n","    (0): Linear(in_features=128, out_features=256, bias=True)\n","    (1): GELU(approximate='none')\n","  )\n","  (layer_6): Sequential(\n","    (0): Linear(in_features=128, out_features=256, bias=True)\n","    (1): GELU(approximate='none')\n","  )\n","  (layer_7): Sequential(\n","    (0): Linear(in_features=128, out_features=256, bias=True)\n","    (1): GELU(approximate='none')\n","  )\n","  (layer_8): Sequential(\n","    (0): Linear(in_features=128, out_features=256, bias=True)\n","    (1): GELU(approximate='none')\n","  )\n","  (layer_9): Sequential(\n","    (0): Linear(in_features=128, out_features=256, bias=True)\n","    (1): GELU(approximate='none')\n","  )\n",")\n","\n","=== Secure Swarm Test ===\n","NodeB memory before: 0.0009027373744174838\n","🔒 Node 2 safely synced with 1\n","NodeB memory after: -0.005850641522556543\n","\n","=== Modification Test ===\n","✅ Added: nn.LayerNorm(128)\n","✅ Added: nn.LayerNorm(128)\n","✅ Added: nn.LayerNorm(128)\n","✅ Added: nn.LayerNorm(128)\n","✅ Added: nn.LayerNorm(128)\n","\n","=== Security Test ===\n","🔒 Node 0 safely synced with 1\n","🔒 Node 0 safely synced with 99\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import time\n","from transformers import GPT2Tokenizer\n","from collections import defaultdict\n","import hmac, hashlib\n","import ast, astunparse, numpy as np # Added ast, astunparse, numpy\n","\n","# --- Robust Self-Modifying DML (Moved from lGTiJ2Rjy7aP) ---\n","class SafeSelfModifyingDML(nn.Module):\n","    def __init__(self, d_model=128):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.code_gen = nn.Sequential(\n","            nn.Linear(d_model, 512),\n","            nn.LayerNorm(512),\n","            nn.Linear(512, 1024)\n","        )\n","        self.memory = nn.Parameter(torch.randn(50, d_model))\n","        self.layer_count = 0\n","        self.safety_whitelist = {\n","            'Module', 'Expr', 'Call', 'Name', 'Load',\n","            'Attribute', 'Constant', 'nn', 'torch'\n","        }\n","\n","    def generate_safe_code(self, x):\n","        \"\"\"Diverse yet secure code generation\"\"\"\n","        logits = self.code_gen(x.mean(dim=1))\n","        pattern_id = torch.argmax(logits) % 6\n","        patterns = [\n","            \"nn.Sequential(nn.Linear(128,256), nn.GELU())\",\n","            \"nn.LayerNorm(128)\",\n","            \"nn.TransformerEncoderLayer(d_model=128, nhead=8)\",\n","            \"lambda: nn.Conv1d(128,64,3)\",\n","            \"nn.Dropout(0.1)\",\n","            \"nn.Identity()\"\n","        ]\n","        return patterns[pattern_id]\n","\n","    def apply_code(self, code_str):\n","        \"\"\"Stable layer addition with clamping\"\"\"\n","        try:\n","            # Security check\n","            tree = ast.parse(code_str)\n","            for node in ast.walk(tree):\n","                if type(node).__name__ not in self.safety_whitelist:\n","                    raise ValueError(f\"Blocked unsafe node: {type(node).__name__}\")\n","\n","            # Execute\n","            new_layer = eval(code_str, {'nn': nn, 'torch': torch})\n","            self.add_module(f\"layer_{self.layer_count}\", new_layer)\n","            self.layer_count += 1\n","\n","            # Stabilize\n","            for p in self.parameters():\n","                p.data = torch.clamp(p.data, -3, 3)  # Critical for long runs\n","\n","            print(f\"✅ Added: {code_str}\")\n","            return True\n","        except Exception as e:\n","            print(f\"❌ Failed: {str(e)[:100]}...\")\n","            return False\n","\n","# --- Secure Swarm Implementation (Moved from lGTiJ2Rjy7aP) ---\n","class SecureSwarmNode:\n","    def __init__(self, node_id, secret_key):\n","        self.id = node_id\n","        self.dml = SafeSelfModifyingDML()\n","        self.peers = []\n","        self.memory_clock = 0\n","        self.key = secret_key.encode()\n","\n","    def _sign(self, data):\n","        return hmac.new(self.key, data, hashlib.sha256).hexdigest()\n","\n","    def sync_memory(self):\n","        \"\"\"Authenticated memory sharing\"\"\"\n","        for peer in self.peers:\n","            # Prepare memory data\n","            mem_bytes = self.dml.memory.data.numpy().tobytes()\n","            signature = self._sign(mem_bytes)\n","\n","            # Verify peer's memory\n","            peer_mem = peer.get_memory()\n","            if peer.verify_signature(peer_mem['data'], peer_mem['sig']):\n","                # Merge memories\n","                self.dml.memory.data = 0.6*self.dml.memory.data + 0.4*peer_mem['data']\n","                self.memory_clock = max(self.memory_clock, peer_mem['clock']) + 1\n","                print(f\"🔒 Node {self.id} safely synced with {peer.id}\")\n","\n","    def get_memory(self):\n","        mem_bytes = self.dml.memory.data.numpy().tobytes()\n","        return {\n","            'data': self.dml.memory.data.clone(),\n","            'sig': self._sign(mem_bytes),\n","            'clock': self.memory_clock\n","        }\n","\n","    def verify_signature(self, data, signature):\n","        data_bytes = data.numpy().tobytes()\n","        correct_sig = hmac.new(self.key, data_bytes, hashlib.sha256).hexdigest()\n","        return hmac.compare_digest(correct_sig, signature)\n","\n","# Task Generator (From Phase 2 - Moved from pJ6U-6O5uf_u)\n","class TaskGenerator(nn.Module):\n","    def __init__(self, d_model=128, num_tasks=6):\n","        super().__init__()\n","        self.task_bank = [\"story\", \"poem\", \"code\", \"riddle\", \"essay\", \"math\"]\n","        self.fc = nn.Sequential(\n","            nn.Linear(d_model, d_model),\n","            nn.ReLU(),\n","            nn.Linear(d_model, num_tasks)\n","        )\n","\n","    def forward(self, memory_state):\n","        logits = self.fc(memory_state.mean(dim=0))\n","        probs = torch.softmax(logits, dim=-1)\n","        task_idx = torch.multinomial(probs, num_samples=1)\n","        return self.task_bank[task_idx]\n","\n","# --- Environment Placeholder ---\n","def sense_environment():\n","    prompt = \"The future of humanity lies in\"\n","    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","    tokens = tokenizer(prompt, return_tensors=\"pt\")\n","    x = torch.randn(1, len(tokens[\"input_ids\"]), 128)\n","    return x\n","\n","# --- Setup ---\n","SECRET = \"agi-agent-key\"\n","node = SecureSwarmNode(0, SECRET)\n","task_gen = TaskGenerator()\n","\n","# --- Live AGI Loop ---\n","def agent_loop():\n","    print(\"🔁 AGI loop started...\")\n","    for step in range(10):  # Simulate 10 thinking cycles\n","        print(f\"\\n🧠 Cycle {step+1}\")\n","\n","        # 1. Observe\n","        x = sense_environment()\n","\n","        # 2. Task Proposal\n","        task = task_gen(node.dml.memory.detach())\n","        print(\"🧭 Proposed Task:\", task)\n","\n","        # 3. Code Generation + Application\n","        code = node.dml.generate_safe_code(x)\n","        success = node.dml.apply_code(code)\n","\n","        # 4. Memory Self-Update\n","        with torch.no_grad():\n","            node.dml.memory.data += 0.01 * torch.randn_like(node.dml.memory.data)\n","\n","        # 5. Sync with swarm (simulated)\n","        node.sync_memory()\n","\n","        # 6. Wait for next cycle\n","        time.sleep(1)\n","\n","# Run\n","if __name__ == \"__main__\":\n","    agent_loop()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_HAOPE60Ofm","executionInfo":{"status":"ok","timestamp":1751689318943,"user_tz":-330,"elapsed":15241,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}},"outputId":"0436909b-1d9a-4c57-af86-eea20f195b8c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["🔁 AGI loop started...\n","\n","🧠 Cycle 1\n","🧭 Proposed Task: essay\n","❌ Failed: Blocked unsafe node: keyword...\n","\n","🧠 Cycle 2\n","🧭 Proposed Task: essay\n","❌ Failed: Blocked unsafe node: Lambda...\n","\n","🧠 Cycle 3\n","🧭 Proposed Task: math\n","✅ Added: nn.Sequential(nn.Linear(128,256), nn.GELU())\n","\n","🧠 Cycle 4\n","🧭 Proposed Task: code\n","✅ Added: nn.Identity()\n","\n","🧠 Cycle 5\n","🧭 Proposed Task: story\n","✅ Added: nn.LayerNorm(128)\n","\n","🧠 Cycle 6\n","🧭 Proposed Task: math\n","✅ Added: nn.Identity()\n","\n","🧠 Cycle 7\n","🧭 Proposed Task: story\n","✅ Added: nn.LayerNorm(128)\n","\n","🧠 Cycle 8\n","🧭 Proposed Task: math\n","✅ Added: nn.Dropout(0.1)\n","\n","🧠 Cycle 9\n","🧭 Proposed Task: story\n","✅ Added: nn.Dropout(0.1)\n","\n","🧠 Cycle 10\n","🧭 Proposed Task: essay\n","❌ Failed: Blocked unsafe node: keyword...\n"]}]},{"cell_type":"code","source":["# # Phase 3 AGI - Optimized Implementation\n","# **Enhanced Features:**\n","# 1. Diverse architecture generation\n","# 2. Adaptive swarm learning\n","# 3. Military-grade security\n","\n","# %%\n","!pip install torch astunparse cryptography\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import ast\n","import astunparse\n","from collections import defaultdict\n","import hmac\n","import hashlib\n","import numpy as np\n","\n","\n","# ## 1. Enhanced Self-Modifying DML\n","\n","# %%\n","class SafeSelfModifyingDML(nn.Module):\n","    def __init__(self, d_model=128):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.code_gen = nn.Sequential(\n","            nn.Linear(d_model, 512),\n","            nn.LayerNorm(512),\n","            nn.GELU(),\n","            nn.Linear(512, 1024)\n","        )\n","        self.memory = nn.Parameter(torch.randn(50, d_model))\n","        self.layer_count = 0\n","        self.safety_whitelist = {\n","            'Module', 'Expr', 'Call', 'Name', 'Load',\n","            'Attribute', 'Constant', 'nn', 'torch'\n","        }\n","\n","    def generate_safe_code(self, x):\n","        \"\"\"Dynamically weighted architecture generation\"\"\"\n","        logits = F.gumbel_softmax(self.code_gen(x.mean(dim=1)), tau=0.7, hard=False)\n","        patterns = [\n","            f\"nn.Sequential(nn.Linear(128,{256//(i+1)}), nn.{act}(), nn.Dropout({0.1*i}))\"\n","            for i, act in enumerate(['GELU','Mish','ReLU','SiLU'] * 2)\n","        ] + [\n","            \"nn.TransformerEncoderLayer(d_model=128, nhead=4)\",\n","            \"nn.Bilinear(128,128,256)\",\n","            \"lambda: nn.Sequential(nn.Conv1d(128,64,3), nn.Mish())\"\n","        ]\n","        # Use modulo to ensure pattern_id is within the range of patterns list\n","        pattern_id = torch.argmax(logits) % len(patterns)\n","        return patterns[pattern_id]\n","\n","    def apply_code(self, code_str):\n","        \"\"\"Stable layer addition with clamping\"\"\"\n","        try:\n","            # Security check\n","            tree = ast.parse(code_str)\n","            for node in ast.walk(tree):\n","                if type(node).__name__ not in self.safety_whitelist:\n","                    raise ValueError(f\"Blocked unsafe node: {type(node).__name__}\")\n","\n","            # Execute\n","            new_layer = eval(code_str, {'nn': nn, 'torch': torch})\n","            self.add_module(f\"layer_{self.layer_count}\", new_layer)\n","            self.layer_count += 1\n","\n","            # Stabilize\n","            for p in self.parameters():\n","                p.data = torch.clamp(p.data, -3, 3)\n","\n","            print(f\"✅ Added: {code_str.split('(')[0]}\")\n","            return True\n","        except Exception as e:\n","            print(f\"❌ Blocked: {str(e)[:100]}...\")\n","            return False\n","\n","# %%\n","# Test architecture diversity\n","print(\"=== ARCHITECTURE DIVERSITY TEST ===\")\n","dml = SafeSelfModifyingDML()\n","test_input = torch.randn(1, 10, 128)\n","\n","unique_architectures = set()\n","for _ in range(15):\n","    code = dml.generate_safe_code(test_input)\n","    dml.apply_code(code)\n","    unique_architectures.add(code.split('(')[0])\n","\n","print(f\"\\nGenerated {len(unique_architectures)} unique layer types:\")\n","print(unique_architectures)\n","\n","\n","# ## 2. Optimized Swarm Learning\n","\n","# %%\n","class SecureSwarmNode:\n","    def __init__(self, node_id, secret_key):\n","        self.id = node_id\n","        self.dml = SafeSelfModifyingDML()\n","        self.peers = []\n","        self.memory_clock = 0\n","        self.key = secret_key.encode()\n","        self.alert_mode = False\n","        self.trust_factor = 1.0\n","\n","    def _sign(self, data):\n","        return hmac.new(\n","            self.key,\n","            data + str(self.memory_clock).encode(),\n","            hashlib.sha3_256\n","        ).hexdigest()\n","\n","    def get_memory(self):\n","        mem_bytes = self.dml.memory.data.numpy().tobytes()\n","        return {\n","            'data': self.dml.memory.data.clone(),\n","            'sig': self._sign(mem_bytes),\n","            'clock': self.memory_clock\n","        }\n","\n","    def verify_signature(self, data, signature):\n","        if self.alert_mode:\n","            print(f\"🛑 Node {self.id} in lockdown\")\n","            return False\n","\n","        try:\n","            data_bytes = data.numpy().tobytes()\n","            correct_sig = hmac.new(\n","                self.key,\n","                data_bytes + str(self.memory_clock).encode(),\n","                hashlib.sha3_256\n","            ).hexdigest()\n","\n","            if not hmac.compare_digest(correct_sig, signature):\n","                raise SecurityError(\"Signature mismatch\")\n","            return True\n","        except Exception as e:\n","            self.alert_mode = True\n","            self.trust_factor *= 0.5\n","            print(f\"🚨 Node {self.id} security alert: {str(e)[:50]}...\")\n","            return False\n","\n","    def sync_memory(self):\n","        \"\"\"Adaptive memory mixing\"\"\"\n","        for peer in self.peers.copy():  # Copy to avoid modification during iteration\n","            peer_mem = peer.get_memory()\n","\n","            if not self.verify_signature(peer_mem['data'], peer_mem['sig']):\n","                self.peers.remove(peer)\n","                continue\n","\n","            # Calculate novelty-based mixing ratio\n","            novelty = 1 - F.cosine_similarity(\n","                self.dml.memory.data.flatten(),\n","                peer_mem['data'].flatten(),\n","                dim=0\n","            ).abs().item()\n","\n","            ratio = min(0.9, self.trust_factor * novelty)\n","            self.dml.memory.data = (1-ratio)*self.dml.memory.data + ratio*peer_mem['data']\n","            self.memory_clock = max(self.memory_clock, peer_mem['clock']) + 1\n","\n","            print(f\"🔀 Node {self.id} <- {ratio:.0%} Node {peer.id} (Novelty={novelty:.2f})\")\n","\n","# %%\n","# Swarm network test\n","print(\"\\n=== SWARM LEARNING TEST ===\")\n","secret = \"dml-phase3-secure-key-!@#\"\n","nodes = [SecureSwarmNode(i, secret) for i in range(3)]\n","\n","# Create ring topology\n","for i in range(3):\n","    nodes[i].peers = [nodes[(i+1)%3]]\n","\n","# Node 0 makes a discovery\n","nodes[0].dml.memory.data.uniform_(-2, 2)\n","\n","# Sync all nodes\n","print(\"\\nInitial Sync:\")\n","for node in nodes[1:]:\n","    node.sync_memory()\n","\n","# Simulate attack\n","print(\"\\nSecurity Test:\")\n","malicious = SecureSwarmNode(99, \"wrong-key\")\n","nodes[0].peers.append(malicious)\n","nodes[0].sync_memory()  # Should trigger security alert\n","\n","\n","# ## 3. Complete System Validation\n","\n","# %%\n","def full_phase3_test():\n","    # Initialize\n","    dml = SafeSelfModifyingDML()\n","    swarm = [SecureSwarmNode(i, \"shared-secret\") for i in range(3)]\n","\n","    # Fully connected swarm\n","    for node in swarm:\n","        node.peers = [n for n in swarm if n != node]\n","\n","    # Part 1: Architecture evolution\n","    print(\"\\n=== ARCHITECTURE EVOLUTION ===\")\n","    test_input = torch.randn(1, 8, 128)\n","    for _ in range(10):\n","        code = dml.generate_safe_code(test_input)\n","        dml.apply_code(code)\n","\n","    # Part 2: Swarm learning\n","    print(\"\\n=== SWARM LEARNING ===\")\n","    swarm[0].dml.memory.data.normal_(mean=1.0, std=0.5)\n","    for node in swarm[1:]:\n","        node.sync_memory()\n","        print(f\"Node {node.id} memory mean: {node.dml.memory.data.mean().item():.4f}\")\n","\n","    # Part 3: Security hardening\n","    print(\"\\n=== SECURITY TEST ===\")\n","    attacker = SecureSwarmNode(666, \"wrong-key\")\n","    swarm[1].peers.append(attacker)\n","    swarm[1].sync_memory()\n","\n","    return dml, swarm\n","\n","trained_dml, swarm_nodes = full_phase3_test()\n","\n","# ## 4. Deployment Preparation\n","\n","# %%\n","# Quantization for edge devices\n","print(\"\\n=== EDGE DEPLOYMENT ===\")\n","quantized_dml = torch.quantization.quantize_dynamic(\n","    trained_dml,\n","    {nn.Linear, nn.LayerNorm},\n","    dtype=torch.qint8\n",")\n","\n","print(\"Original size:\", sum(p.numel() for p in trained_dml.parameters()))\n","print(\"Quantized size:\", sum(p.numel() for p in quantized_dml.parameters()))\n","\n","# Save for deployment\n","torch.jit.save(torch.jit.script(quantized_dml), \"phase3_quantized.pt\")\n","print(\"Model saved for edge deployment!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JWLCSoHZ1sFr","executionInfo":{"status":"ok","timestamp":1751689717656,"user_tz":-330,"elapsed":9590,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}},"outputId":"7168edd4-2251-48ee-98a1-f2ce229f5585"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (1.6.3)\n","Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (43.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse) (0.45.1)\n","Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse) (1.17.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","=== ARCHITECTURE DIVERSITY TEST ===\n","✅ Added: nn.Sequential\n","✅ Added: nn.Sequential\n","✅ Added: nn.Sequential\n","✅ Added: nn.Sequential\n","✅ Added: nn.Sequential\n","✅ Added: nn.Sequential\n","✅ Added: nn.Sequential\n","✅ Added: nn.Sequential\n","✅ Added: nn.Sequential\n","✅ Added: nn.Sequential\n","❌ Blocked: Blocked unsafe node: Lambda...\n","✅ Added: nn.Sequential\n","❌ Blocked: Blocked unsafe node: keyword...\n","❌ Blocked: Blocked unsafe node: Lambda...\n","✅ Added: nn.Sequential\n","\n","Generated 3 unique layer types:\n","{'nn.TransformerEncoderLayer', 'lambda: nn.Sequential', 'nn.Sequential'}\n","\n","=== SWARM LEARNING TEST ===\n","\n","Initial Sync:\n","🔀 Node 1 <- 90% Node 2 (Novelty=0.99)\n","🔀 Node 2 <- 90% Node 0 (Novelty=0.99)\n","\n","Security Test:\n","🚨 Node 0 security alert: name 'SecurityError' is not defined...\n","🛑 Node 0 in lockdown\n","\n","=== ARCHITECTURE EVOLUTION ===\n","✅ Added: nn.Sequential\n","✅ Added: nn.Sequential\n","❌ Blocked: Blocked unsafe node: keyword...\n","✅ Added: nn.Sequential\n","✅ Added: nn.Bilinear\n","✅ Added: nn.Sequential\n","✅ Added: nn.Sequential\n","✅ Added: nn.Bilinear\n","❌ Blocked: Blocked unsafe node: Lambda...\n","✅ Added: nn.Sequential\n","\n","=== SWARM LEARNING ===\n","🔀 Node 1 <- 90% Node 0 (Novelty=0.99)\n","🚨 Node 1 security alert: name 'SecurityError' is not defined...\n","Node 1 memory mean: 0.8993\n","🔀 Node 2 <- 90% Node 0 (Novelty=1.00)\n","🔀 Node 2 <- 1% Node 1 (Novelty=0.01)\n","Node 2 memory mean: 0.9000\n","\n","=== SECURITY TEST ===\n","🛑 Node 1 in lockdown\n","🛑 Node 1 in lockdown\n","\n","=== EDGE DEPLOYMENT ===\n","Original size: 9060402\n","Quantized size: 8396544\n","Model saved for edge deployment!\n"]}]},{"cell_type":"code","source":["# reward_evaluator.py\n","\n","import torch\n","import torch.nn.functional as F\n","from collections import defaultdict\n","\n","class RewardEvaluator:\n","    def __init__(self):\n","        self.task_stats = defaultdict(list)  # e.g., {\"story\": [0.7, 0.9, ...]}\n","\n","    def evaluate_output(self, task_type, output_text):\n","        \"\"\"\n","        Assign a reward score (0 to 1) based on output quality heuristics.\n","        You can expand this with BLEU, GPT2 perplexity, or exact match.\n","        \"\"\"\n","        score = 0.0\n","        if task_type == \"story\":\n","            score = 1.0 if \"once upon a time\" in output_text.lower() else 0.7\n","        elif task_type == \"math\":\n","            score = 1.0 if \"=\" in output_text or output_text.strip().isdigit() else 0.6\n","        elif task_type == \"code\":\n","            score = 1.0 if \"def \" in output_text or \"import\" in output_text else 0.5\n","        elif task_type == \"poem\":\n","            score = 0.8 if output_text.count(\"\\n\") > 3 else 0.5\n","        else:\n","            score = 0.6  # fallback baseline\n","\n","        self.task_stats[task_type].append(score)\n","        return score\n","\n","    def update_memory(self, dml_model, reward_score):\n","        \"\"\"Adjust DML memory weights based on reward feedback.\"\"\"\n","        with torch.no_grad():\n","            norm_reward = torch.tensor(reward_score).clamp(0.0, 1.0)\n","            dml_model.memory.data *= 0.95  # decay\n","            dml_model.memory.data += norm_reward * 0.05  # reinforce\n","\n","    def log_feedback(self, task_type, reward_score):\n","        print(f\"📊 Task: {task_type}, Reward Score: {reward_score:.2f}\")\n"],"metadata":{"id":"AkzJpiPH5PSG","executionInfo":{"status":"ok","timestamp":1751690577857,"user_tz":-330,"elapsed":21,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# test_reward_phase4.py\n","\n","import torch\n","import torch.nn as nn # Added nn\n","import torch.nn.functional as F\n","from collections import defaultdict\n","\n","# --- Robust Self-Modifying DML (Moved from JWLCSoHZ1sFr) ---\n","class SafeSelfModifyingDML(nn.Module):\n","    def __init__(self, d_model=128):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.code_gen = nn.Sequential(\n","            nn.Linear(d_model, 512),\n","            nn.LayerNorm(512),\n","            nn.GELU(),\n","            nn.Linear(512, 1024)\n","        )\n","        self.memory = nn.Parameter(torch.randn(50, d_model))\n","        self.layer_count = 0\n","        # Assuming safety_whitelist and related methods are not directly used in this test cell,\n","        # but are part of the SafeSelfModifyingDML definition from the previous phase.\n","        # If they are needed, they should be included here as well.\n","\n","    def generate_safe_code(self, x):\n","        # This method is likely not needed for this specific test cell,\n","        # as the test is focused on the RewardEvaluator.\n","        # Keeping a minimal version or placeholder if the DML model\n","        # architecture itself is needed for instantiation.\n","        pass # Or a minimal implementation if required for instantiation\n","\n","    def apply_code(self, code_str):\n","         # This method is likely not needed for this specific test cell.\n","         pass # Or a minimal implementation if required for instantiation\n","\n","\n","# reward_evaluator.py (Moved from AkzJpiPH5PSG)\n","class RewardEvaluator:\n","    def __init__(self):\n","        self.task_stats = defaultdict(list)  # e.g., {\"story\": [0.7, 0.9, ...]}\n","\n","    def evaluate_output(self, task_type, output_text):\n","        \"\"\"\n","        Assign a reward score (0 to 1) based on output quality heuristics.\n","        You can expand this with BLEU, GPT2 perplexity, or exact match.\n","        \"\"\"\n","        score = 0.0\n","        if task_type == \"story\":\n","            score = 1.0 if \"once upon a time\" in output_text.lower() else 0.7\n","        elif task_type == \"math\":\n","            score = 1.0 if \"=\" in output_text or output_text.strip().isdigit() else 0.6\n","        elif task_type == \"code\":\n","            score = 1.0 if \"def \" in output_text or \"import\" in output_text else 0.5\n","        elif task_type == \"poem\":\n","            score = 0.8 if output_text.count(\"\\n\") > 3 else 0.5\n","        else:\n","            score = 0.6  # fallback baseline\n","\n","        self.task_stats[task_type].append(score)\n","        return score\n","\n","    def update_memory(self, dml_model, reward_score):\n","        \"\"\"Adjust DML memory weights based on reward feedback.\"\"\"\n","        with torch.no_grad():\n","            norm_reward = torch.tensor(reward_score).clamp(0.0, 1.0)\n","            dml_model.memory.data *= 0.95  # decay\n","            dml_model.memory.data += norm_reward * 0.05  # reinforce\n","\n","    def log_feedback(self, task_type, reward_score):\n","        print(f\"📊 Task: {task_type}, Reward Score: {reward_score:.2f}\")\n","\n","\n","# Initialize components\n","# Note: SafeSelfModifyingDML is likely a complex model and instantiating it directly\n","# might require additional imports (like ast, astunparse, numpy, hmac, hashlib)\n","# and potentially a different __init__ if it expects specific arguments related\n","# to the previous phases (like secret keys for swarm).\n","# For this specific test of RewardEvaluator, we might only need a mock DML model\n","# or a simplified version that has the 'memory' attribute.\n","# Assuming SafeSelfModifyingDML can be instantiated with just d_model=128 for this test.\n","try:\n","    dml_model = SafeSelfModifyingDML(d_model=128)\n","except Exception as e:\n","    print(f\"Could not instantiate SafeSelfModifyingDML: {e}\")\n","    print(\"Using a mock DML model for RewardEvaluator test.\")\n","    # Create a mock DML model with a 'memory' attribute for testing\n","    class MockDMLModel:\n","        def __init__(self, d_model=128, mem_size=50):\n","            self.memory = torch.nn.Parameter(torch.randn(mem_size, d_model))\n","    dml_model = MockDMLModel(d_model=128)\n","\n","\n","evaluator = RewardEvaluator()\n","\n","# Fake tasks and outputs (you can replace these with real generated results)\n","task_outputs = [\n","    (\"story\", \"Once upon a time, a drone discovered intelligence.\"),\n","    (\"math\", \"3 + 4 = 7\"),\n","    (\"code\", \"def add(x, y): return x + y\"),\n","    (\"poem\", \"Roses are red\\nViolets are blue\\nAGI is rising\\nRight from this view.\"),\n","    (\"essay\", \"Technology is evolving fast.\"),\n","]\n","\n","# Simulate evaluation loop\n","for task_type, output_text in task_outputs:\n","    score = evaluator.evaluate_output(task_type, output_text)\n","    evaluator.update_memory(dml_model, score)\n","    evaluator.log_feedback(task_type, score)\n","\n","# Check memory stats\n","print(\"\\nUpdated Memory Mean:\", dml_model.memory.data.mean().item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndOHV_ON5fdC","executionInfo":{"status":"ok","timestamp":1751690677598,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}},"outputId":"ab9d0270-bbd9-4903-cca7-4b4fee5ac40c"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["📊 Task: story, Reward Score: 1.00\n","📊 Task: math, Reward Score: 1.00\n","📊 Task: code, Reward Score: 1.00\n","📊 Task: poem, Reward Score: 0.50\n","📊 Task: essay, Reward Score: 0.60\n","\n","Updated Memory Mean: 0.19906997680664062\n"]}]},{"cell_type":"code","source":["# phase5_goal_manager.py\n","\n","import random\n","from collections import defaultdict\n","\n","class GoalManager:\n","    def __init__(self):\n","        self.task_rewards = defaultdict(list)\n","        self.task_types = [\"story\", \"math\", \"code\", \"poem\", \"essay\"]\n","\n","    def select_task(self):\n","        \"\"\"Choose task type based on past rewards (exploit vs explore)\"\"\"\n","        scores = {t: (sum(self.task_rewards[t]) / len(self.task_rewards[t]) if self.task_rewards[t] else 0.5)\n","                  for t in self.task_types}\n","\n","        # Softmax probability for task selection\n","        total = sum(scores.values())\n","        probs = [scores[t] / total for t in self.task_types]\n","\n","        return random.choices(self.task_types, weights=probs, k=1)[0]\n","\n","    def register_reward(self, task_type, reward):\n","        self.task_rewards[task_type].append(reward)\n"],"metadata":{"id":"8VKvNdWU6TqM","executionInfo":{"status":"ok","timestamp":1751690859299,"user_tz":-330,"elapsed":41,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# agi_loop.py\n","\n","# phase5_goal_manager.py\n","import random\n","from collections import defaultdict\n","\n","class GoalManager:\n","    def __init__(self):\n","        self.task_rewards = defaultdict(list)\n","        self.task_types = [\"story\", \"math\", \"code\", \"poem\", \"essay\"]\n","\n","    def select_task(self):\n","        \"\"\"Choose task type based on past rewards (exploit vs explore)\"\"\"\n","        scores = {t: (sum(self.task_rewards[t]) / len(self.task_rewards[t]) if self.task_rewards[t] else 0.5)\n","                  for t in self.task_types}\n","\n","        # Softmax probability for task selection\n","        total = sum(scores.values())\n","        probs = [scores[t] / total for t in self.task_types]\n","\n","        return random.choices(self.task_types, weights=probs, k=1)[0]\n","\n","    def register_reward(self, task_type, reward):\n","        self.task_rewards[task_type].append(reward)\n","\n","\n","# from phase4_reward_evaluator import RewardEvaluator # Removed import\n","# from phase3_secure_dml import SafeSelfModifyingDML # Removed import\n","import torch\n","\n","# --- Reward Evaluator (Moved from ndOHV_ON5fdC) ---\n","import torch.nn.functional as F # Added F\n","class RewardEvaluator:\n","    def __init__(self):\n","        self.task_stats = defaultdict(list)  # e.g., {\"story\": [0.7, 0.9, ...]}\n","\n","    def evaluate_output(self, task_type, output_text):\n","        \"\"\"\n","        Assign a reward score (0 to 1) based on output quality heuristics.\n","        You can expand this with BLEU, GPT2 perplexity, or exact match.\n","        \"\"\"\n","        score = 0.0\n","        if task_type == \"story\":\n","            score = 1.0 if \"once upon a time\" in output_text.lower() else 0.7\n","        elif task_type == \"math\":\n","            score = 1.0 if \"=\" in output_text or output_text.strip().isdigit() else 0.6\n","        elif task_type == \"code\":\n","            score = 1.0 if \"def \" in output_text or \"import\" in output_text else 0.5\n","        elif task_type == \"poem\":\n","            score = 0.8 if output_text.count(\"\\n\") > 3 else 0.5\n","        else:\n","            score = 0.6  # fallback baseline\n","\n","        self.task_stats[task_type].append(score)\n","        return score\n","\n","    def update_memory(self, dml_model, reward_score):\n","        \"\"\"Adjust DML memory weights based on reward feedback.\"\"\"\n","        with torch.no_grad():\n","            norm_reward = torch.tensor(reward_score).clamp(0.0, 1.0)\n","            dml_model.memory.data *= 0.95  # decay\n","            dml_model.memory.data += norm_reward * 0.05  # reinforce\n","\n","    def log_feedback(self, task_type, reward_score):\n","        print(f\"📊 Task: {task_type}, Reward Score: {reward_score:.2f}\")\n","\n","# --- Safe Self-Modifying DML (Moved from JWLCSoHZ1sFr) ---\n","import torch.nn as nn # Added nn\n","import ast # Added ast\n","import astunparse # Added astunparse\n","import numpy as np # Added numpy\n","class SafeSelfModifyingDML(nn.Module):\n","    def __init__(self, d_model=128):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.code_gen = nn.Sequential(\n","            nn.Linear(d_model, 512),\n","            nn.LayerNorm(512),\n","            nn.GELU(),\n","            nn.Linear(512, 1024)\n","        )\n","        self.memory = nn.Parameter(torch.randn(50, d_model))\n","        self.layer_count = 0\n","        self.safety_whitelist = {\n","            'Module', 'Expr', 'Call', 'Name', 'Load',\n","            'Attribute', 'Constant', 'nn', 'torch'\n","        }\n","\n","    def generate_safe_code(self, x):\n","        \"\"\"Dynamically weighted architecture generation\"\"\"\n","        logits = F.gumbel_softmax(self.code_gen(x.mean(dim=1)), tau=0.7, hard=False)\n","        patterns = [\n","            f\"nn.Sequential(nn.Linear(128,{256//(i+1)}), nn.{act}(), nn.Dropout({0.1*i}))\"\n","            for i, act in enumerate(['GELU','Mish','ReLU','SiLU'] * 2)\n","        ] + [\n","            \"nn.TransformerEncoderLayer(d_model=128, nhead=4)\",\n","            \"nn.Bilinear(128,128,256)\",\n","            \"lambda: nn.Sequential(nn.Conv1d(128,64,3), nn.Mish())\"\n","        ]\n","        # Use modulo to ensure pattern_id is within the range of patterns list\n","        pattern_id = torch.argmax(logits) % len(patterns)\n","        return patterns[pattern_id]\n","\n","    def apply_code(self, code_str):\n","        \"\"\"Stable layer addition with clamping\"\"\"\n","        try:\n","            # Security check\n","            tree = ast.parse(code_str)\n","            for node in ast.walk(tree):\n","                if type(node).__name__ not in self.safety_whitelist:\n","                    raise ValueError(f\"Blocked unsafe node: {type(node).__name__}\")\n","\n","            # Execute\n","            new_layer = eval(code_str, {'nn': nn, 'torch': torch})\n","            self.add_module(f\"layer_{self.layer_count}\", new_layer)\n","            self.layer_count += 1\n","\n","            # Stabilize\n","            for p in self.parameters():\n","                p.data = torch.clamp(p.data, -3, 3)\n","\n","            print(f\"✅ Added: {code_str.split('(')[0]}\")\n","            return True\n","        except Exception as e:\n","            print(f\"❌ Blocked: {str(e)[:100]}...\")\n","            return False\n","\n","\n","# Initialize system\n","dml = SafeSelfModifyingDML()\n","evaluator = RewardEvaluator()\n","goals = GoalManager()\n","\n","task_templates = {\n","    \"story\": \"Once upon a time, AI evolved...\",\n","    \"math\": \"2 + 3 = 5\",\n","    \"code\": \"def hello(): print('Hello World')\",\n","    \"poem\": \"Dreams flow deep\\nCode runs in sleep\\n...\",\n","    \"essay\": \"The future of AI is bright and uncertain.\"\n","}\n","\n","# Loop\n","print(\"\\n🔁 Starting AGI Main Loop (5 Cycles)\")\n","for i in range(5):\n","    print(f\"\\n🧠 Cycle {i+1}\")\n","    task = goals.select_task()\n","    print(f\"🧭 Selected Task: {task}\")\n","\n","    output = task_templates[task]\n","    reward = evaluator.evaluate_output(task, output)\n","    evaluator.update_memory(dml, reward)\n","    goals.register_reward(task, reward)\n","    evaluator.log_feedback(task, reward)\n","\n","print(\"\\n📌 AGI Loop Complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"354sSIVz6V0n","executionInfo":{"status":"ok","timestamp":1751690899796,"user_tz":-330,"elapsed":27,"user":{"displayName":"Sunny Thakur","userId":"00986316513702009163"}},"outputId":"3d1a77c6-c98a-4320-e3b1-44944a63f864"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🔁 Starting AGI Main Loop (5 Cycles)\n","\n","🧠 Cycle 1\n","🧭 Selected Task: story\n","📊 Task: story, Reward Score: 1.00\n","\n","🧠 Cycle 2\n","🧭 Selected Task: code\n","📊 Task: code, Reward Score: 1.00\n","\n","🧠 Cycle 3\n","🧭 Selected Task: story\n","📊 Task: story, Reward Score: 1.00\n","\n","🧠 Cycle 4\n","🧭 Selected Task: story\n","📊 Task: story, Reward Score: 1.00\n","\n","🧠 Cycle 5\n","🧭 Selected Task: code\n","📊 Task: code, Reward Score: 1.00\n","\n","📌 AGI Loop Complete.\n"]}]}]}